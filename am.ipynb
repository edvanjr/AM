{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import make_blobs, make_moons, make_regression, load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import csv\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dados = pd.read_csv('data.csv')\n",
    "\n",
    "# removed from shape view\n",
    "dados = dados.drop(columns='REGION-PIXEL-COUNT')\n",
    "dados = dados.drop(columns='SHORT-LINE-DENSITY-5')\n",
    "dados = dados.drop(columns='SHORT-LINE-DENSITY-2')\n",
    "\n",
    "# removed from RGB view\n",
    "dados = dados.drop(columns='INTENSITY-MEAN')\n",
    "dados = dados.drop(columns='RAWRED-MEAN')\n",
    "dados = dados.drop(columns='RAWBLUE-MEAN')\n",
    "dados = dados.drop(columns='RAWGREEN-MEAN')\n",
    "dados = dados.drop(columns='EXRED-MEAN')\n",
    "dados = dados.drop(columns='EXBLUE-MEAN')\n",
    "\n",
    "dados = np.asarray(dados)\n",
    "X = np.copy(dados)\n",
    "y_names = X[:, 0]\n",
    "X = np.array(X[:, 1:], dtype='f')\n",
    "labels = set(y_names)\n",
    "classes_dict = {}\n",
    "\n",
    "i = 0\n",
    "\n",
    "for label in labels:\n",
    "    classes_dict[label] = i\n",
    "    i += 1\n",
    "\n",
    "y_numbers = [classes_dict[y_names[i]] for i in range(y_names.shape[0])]\n",
    "y_numbers = np.array(y_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificador bayesiano gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesClassifier:\n",
    "    mu = None\n",
    "    cov = None\n",
    "    n_classes = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        a = None\n",
    "    \n",
    "    def pred(self, x):\n",
    "        prob_vect = np.zeros(self.n_classes)\n",
    "        \n",
    "        for i in range(self.n_classes):\n",
    "            mnormal = multivariate_normal(mean=self.mu[i], cov=self.cov[i])\n",
    "            \n",
    "            prior = 1. / self.n_classes\n",
    "            \n",
    "            prob_vect[i] = prior * mnormal.pdf(x)\n",
    "            summ = 0.\n",
    "            \n",
    "            for j in range(self.n_classes):\n",
    "                mnormal = multivariate_normal(mean=self.mu[j], cov=self.cov[j])\n",
    "                summ += prior * mnormal.pdf(x)\n",
    "            \n",
    "            prob_vect[i] = prob_vect[i] / summ\n",
    "        \n",
    "        return prob_vect\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.mu = []\n",
    "        self.cov = []\n",
    "        self.n_classes = np.max(y) + 1\n",
    "    \n",
    "        for c in range(self.n_classes):\n",
    "            Xc = X[y==c]\n",
    "\n",
    "            mu_c = np.mean(Xc, axis=0)\n",
    "            self.mu.append(mu_c)\n",
    "            \n",
    "            cov_c = np.zeros((X.shape[1], X.shape[1]))\n",
    "            \n",
    "            for i in range(Xc.shape[1]):\n",
    "                for j in range(Xc.shape[1]):\n",
    "                    if i == j:\n",
    "                        cov_c[i,j] = np.inner(Xc[:,i] - mu_c[i], Xc[:,j] - mu_c[j])\n",
    "            \n",
    "            cov_c = cov_c / float(X.shape[0])\n",
    "            self.cov.append(cov_c)\n",
    "        \n",
    "        self.mu = np.asarray(self.mu)\n",
    "        self.cov = np.asarray(self.cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flavi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-062e4fe4112b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m             \u001b[0mypred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbc_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mypred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-62e5eca8f4be>\u001b[0m in \u001b[0;36mpred\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m                 \u001b[0mmnormal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultivariate_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m                 \u001b[0msumm\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mprior\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmnormal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\stats\\_multivariate.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, mean, cov, allow_singular, seed)\u001b[0m\n\u001b[0;32m    355\u001b[0m         return multivariate_normal_frozen(mean, cov,\n\u001b[0;32m    356\u001b[0m                                           \u001b[0mallow_singular\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_singular\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m                                           seed=seed)\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_process_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\stats\\_multivariate.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mean, cov, allow_singular, seed, maxpts, abseps, releps)\u001b[0m\n\u001b[0;32m    725\u001b[0m         self.dim, self.mean, self.cov = self._dist._process_parameters(\n\u001b[0;32m    726\u001b[0m                                                             None, mean, cov)\n\u001b[1;32m--> 727\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcov_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_PSD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_singular\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_singular\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmaxpts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m             \u001b[0mmaxpts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000000\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\stats\\_multivariate.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, M, cond, rcond, lower, check_finite, allow_singular)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meigh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_finite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m         \u001b[0meps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_eigvalsh_to_eps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcond\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'the input matrix must be positive semidefinite'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\stats\\_multivariate.py\u001b[0m in \u001b[0;36m_eigvalsh_to_eps\u001b[1;34m(spectrum, cond, rcond)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mfactor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'f'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1E3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'd'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1E6\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mcond\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0meps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcond\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspectrum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   2318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2319\u001b[0m     return _methods._amax(a, axis=axis,\n\u001b[1;32m-> 2320\u001b[1;33m                           out=out, **kwargs)\n\u001b[0m\u001b[0;32m   2321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# small reductions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_amax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "output_1 = []\n",
    "output_2 = []\n",
    "output_3 = []\n",
    "\n",
    "for i in range(30):\n",
    "    # outputs by iteration\n",
    "    iter_output_1 = []\n",
    "    iter_output_2 = []\n",
    "    iter_output_3 = []\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=i)\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y_numbers):\n",
    "        view_1 = np.copy(X[:, 0:6])\n",
    "        view_2 = np.copy(X[:, 6:])\n",
    "        view_3 = np.copy(X)\n",
    "        \n",
    "        X_train, X_test = view_1[train_index], view_1[test_index]\n",
    "        y_train, y_test = y_numbers[train_index], y_numbers[test_index]\n",
    "        bc_1 = BayesClassifier()\n",
    "        bc_1.fit(X_train, y_train)\n",
    "        \n",
    "        hit = 0.\n",
    "\n",
    "        for i in range(X_test.shape[0]):\n",
    "            ypred = bc_1.pred(X_test[i])\n",
    "\n",
    "            if np.argmax(ypred) == y_test[i]:\n",
    "                hit += 1\n",
    "        \n",
    "        iter_output_1.append(hit / X_test.shape[0])\n",
    "        \n",
    "        X_train, X_test = view_2[train_index], view_2[test_index]\n",
    "        y_train, y_test = y_numbers[train_index], y_numbers[test_index]\n",
    "        bc_2 = BayesClassifier()\n",
    "        bc_2.fit(X_train, y_train)\n",
    "        \n",
    "        hit = 0.\n",
    "\n",
    "        for i in range(X_test.shape[0]):\n",
    "            ypred = bc_2.pred(X_test[i])\n",
    "\n",
    "            if np.argmax(ypred) == y_test[i]:\n",
    "                hit += 1\n",
    "        \n",
    "        iter_output_2.append(hit / X_test.shape[0])\n",
    "        \n",
    "        X_train, X_test = view_3[train_index], view_3[test_index]\n",
    "        y_train, y_test = y_numbers[train_index], y_numbers[test_index]\n",
    "        bc_3 = BayesClassifier()\n",
    "        bc_3.fit(X_train, y_train)\n",
    "        \n",
    "        hit = 0.\n",
    "\n",
    "        for i in range(X_test.shape[0]):\n",
    "            ypred = bc_3.pred(X_test[i])\n",
    "\n",
    "            if np.argmax(ypred) == y_test[i]:\n",
    "                hit += 1\n",
    "        \n",
    "        iter_output_3.append(hit / X_test.shape[0])\n",
    "    \n",
    "    output_1.append(iter_output_1)\n",
    "    output_2.append(iter_output_2)\n",
    "    output_3.append(iter_output_3)\n",
    "\n",
    "with open('output/bayesian_v1', 'w') as output_file_1:\n",
    "    wr = csv.writer(output_file_1, quoting=csv.QUOTE_NONE)\n",
    "    for row in output_1:\n",
    "        wr.writerow(row)\n",
    "\n",
    "with open('output/bayesian_v2', 'w') as output_file_2:\n",
    "    wr = csv.writer(output_file_2, quoting=csv.QUOTE_NONE)\n",
    "    for row in output_2:\n",
    "        wr.writerow(row)\n",
    "\n",
    "with open('output/bayesian_v3', 'w') as output_file_3:\n",
    "    wr = csv.writer(output_file_3, quoting=csv.QUOTE_NONE)\n",
    "    for row in output_3:\n",
    "        wr.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimador de Parzen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines_by_class(X, y):\n",
    "    unique_class = np.unique(y)\n",
    "    index = {}\n",
    "    \n",
    "    for i in unique_class:\n",
    "        index[i] = {'x' : X[np.where(y==i)[0]], 'y' : y[np.where(y==i)][0]}\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parzen_estimation(x_train, y_train, h):\n",
    "    data_by_class = get_lines_by_class(x_train, y_train)\n",
    "    density = {}\n",
    "    \n",
    "    for i in data_by_class:\n",
    "        kde = KernelDensity(kernel='gaussian', bandwidth=h).fit(data_by_class[i]['x'])\n",
    "        density[i] = kde\n",
    "    \n",
    "    return density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_bandwidth(x_train, y_train):\n",
    "    bandwidths = [0.1, 0.8, 1.5, 2.2, 2.9, 3.6, 4.3, 5.0, 5.7, 6.4]\n",
    "    X_trn, X_validation, y_trn, y_validation = train_test_split(x_train, y_train, test_size=0.20, random_state=0)\n",
    "    \n",
    "    precision_of_h = {}\n",
    "    \n",
    "    for h in bandwidths:\n",
    "        #tenho 7 kdes para h\n",
    "        modelos_kde_hi = parzen_estimation(X_trn, y_trn, h)\n",
    "        priori_probability = 1. / 7.\n",
    "        predict_hi, _ = predict(modelos_kde_hi, X_validation, priori_probability)\n",
    "        precision_of_h[h] = precision(y_validation, predict_hi)\n",
    "\n",
    "    return max([a for a, b in precision_of_h.items() if b == max([v for idx, v in precision_of_h.items()])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_actual, prediction):\n",
    "    j = 0\n",
    "    positive = 0\n",
    "    \n",
    "    for i in prediction:\n",
    "        if i == y_actual[j]:\n",
    "            positive = positive + 1\n",
    "        \n",
    "        j = j + 1\n",
    "    \n",
    "    return positive / len(y_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_max_class(results):\n",
    "    mx = np.max([results[r] for r in results])\n",
    "    \n",
    "    for i in results:\n",
    "        if(len(np.where(results[i]==mx)[0]) > 0):\n",
    "            return i\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(models, x_validation, priori):\n",
    "    posteriori = {}\n",
    "    prediction_cls = []\n",
    "    prediction = []\n",
    "    \n",
    "    for line in x_validation:\n",
    "        sum_evidences = np.sum([np.exp(models[values].score_samples(line.reshape((1, line.shape[0]))) \\\n",
    "                                       + np.log(priori)) for values in models])\n",
    "        \n",
    "        for i in models:\n",
    "            posteriori[i] = np.exp(models[i].score_samples(line.reshape((1, line.shape[0]))) \\\n",
    "                                   + np.log(priori)) / sum_evidences\n",
    "        \n",
    "        prediction_cls.append(copy.copy(posteriori))\n",
    "        prediction.append(choose_max_class(posteriori))\n",
    "    \n",
    "    return prediction, prediction_cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flavi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\flavi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-c765838b8a8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mview_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mbandwidth_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimate_bandwidth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mview_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_numbers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mmodel_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparzen_estimation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mview_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_numbers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbandwidth_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mprediction_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mview_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m7.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-16ae302322a4>\u001b[0m in \u001b[0;36mestimate_bandwidth\u001b[1;34m(x_train, y_train)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mmodelos_kde_hi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparzen_estimation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_trn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_trn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mpriori_probability\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m7.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mpredict_hi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelos_kde_hi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpriori_probability\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mprecision_of_h\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_hi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-2cda2a6491dd>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(models, x_validation, priori)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx_validation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0msum_evidences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m                                        \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpriori\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m   1880\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1881\u001b[0m     return _methods._sum(a, axis=axis, dtype=dtype,\n\u001b[1;32m-> 1882\u001b[1;33m                          out=out, **kwargs)\n\u001b[0m\u001b[0;32m   1883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1884\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_prod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "output_1 = []\n",
    "output_2 = []\n",
    "output_3 = []\n",
    "\n",
    "for i in range(30):\n",
    "    # outputs by iteration\n",
    "    iter_output_1 = []\n",
    "    iter_output_2 = []\n",
    "    iter_output_3 = []\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=i)\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y_numbers):\n",
    "        # shape view\n",
    "        view_1 = pd.DataFrame(X).iloc[:, :6].values\n",
    "\n",
    "        # RGB view\n",
    "        view_2 = pd.DataFrame(X).iloc[:, 6:].values\n",
    "\n",
    "        # complete view\n",
    "        view_3 = X\n",
    "\n",
    "        bandwidth_1 = estimate_bandwidth(view_1[train_index], y_numbers[train_index])\n",
    "        model_1 = parzen_estimation(view_1[train_index], y_numbers[train_index], bandwidth_1)\n",
    "        prediction_1, _ = predict(model_1, view_1[test_index], 1. / 7.)\n",
    "        hit_rate_1 = precision([z for z in y_numbers[test_index]], prediction_1)\n",
    "        \n",
    "        iter_output_1.append(hit_rate_1)\n",
    "\n",
    "        bandwidth_2 = estimate_bandwidth(view_2[train_index], y_numbers[train_index])\n",
    "        model_2 = parzen_estimation(view_2[train_index], y_numbers[train_index], bandwidth_2)\n",
    "        prediction_2, _ = predict(model_2, view_2[test_index], 1. / 7.)\n",
    "        hit_rate_2 = precision([z for z in y_numbers[test_index]], prediction_2)\n",
    "\n",
    "        iter_output_2.append(hit_rate_2)\n",
    "\n",
    "        bandwidth_3 = estimate_bandwidth(view_3[train_index], y_numbers[train_index])\n",
    "        model_3 = parzen_estimation(view_3[train_index], y_numbers[train_index], bandwidth_3)\n",
    "        prediction_3, _ = predict(model_3, view_3[test_index], 1. / 7.)\n",
    "        hit_rate_3 = precision([z for z in y_numbers[test_index]], prediction_3)\n",
    "        \n",
    "        iter_output_3.append(hit_rate_3)\n",
    "    \n",
    "    output_1.append(iter_output_1)\n",
    "    output_2.append(iter_output_2)\n",
    "    output_3.append(iter_output_3)\n",
    "\n",
    "with open('output/parzen_v1', 'w') as output_file_1:\n",
    "    wr = csv.writer(output_file_1, quoting=csv.QUOTE_NONE)\n",
    "    for row in output_1:\n",
    "        wr.writerow(row)\n",
    "\n",
    "with open('output/parzen_v2', 'w') as output_file_2:\n",
    "    wr = csv.writer(output_file_2, quoting=csv.QUOTE_NONE)\n",
    "    for row in output_2:\n",
    "        wr.writerow(row)\n",
    "\n",
    "with open('output/parzen_v3', 'w') as output_file_3:\n",
    "    wr = csv.writer(output_file_3, quoting=csv.QUOTE_NONE)\n",
    "    for row in output_3:\n",
    "        wr.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificador por regra da soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifiers(X_train, y_train):\n",
    "    bayesian_model = BayesClassifier()\n",
    "    bayesian_model.fit(X_train, y_train)\n",
    "    \n",
    "    h = estimate_bandwidth(X_train, y_train)\n",
    "    parzen_model = parzen_estimation(X_train, y_train, h)\n",
    "    \n",
    "    return bayesian_model, parzen_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum_classifier_hit_rate(bayesian_model, parzen_model, X_test, y_test):\n",
    "    posteriori_bayesian = []\n",
    "    \n",
    "    for i in range(X_test.shape[0]):\n",
    "        posterior_x = bayesian_model.pred(X_test[i])\n",
    "        dict_posterior_x = {}\n",
    "        \n",
    "        for j in range(len(posterior_x)):\n",
    "            dict_posterior_x[j] = np.array([posterior_x[j]])\n",
    "            \n",
    "        posteriori_bayesian.append(dict_posterior_x)\n",
    "    \n",
    "    _, posteriori_parzen = predict(parzen_model, X_test, 1. / 7.)\n",
    "    \n",
    "    hit = 0.\n",
    "    \n",
    "    sums_bayesian_parzen = []\n",
    "    y_predicted = []\n",
    "    \n",
    "    for j in range(len(posteriori_bayesian)):\n",
    "        posteriori_bayesian_j = [float(np.reshape(v, ())) for v in posteriori_bayesian[j].values()]\n",
    "        posteriori_parzen_j = [float(np.reshape(v, ())) for v in posteriori_parzen[j].values()]\n",
    "        \n",
    "        sums_bayesian_parzen.append([sum(v) for v in zip(posteriori_bayesian_j, posteriori_parzen_j)])\n",
    "    \n",
    "    y_predicted = [np.argmax(s) for s in sums_bayesian_parzen]\n",
    "    \n",
    "    return precision(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flavi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\flavi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-dd24284ed210>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mview_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mbayesian_model_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparzen_model_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_classifiers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mview_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_numbers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mhit_rate_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_sum_classifier_hit_rate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbayesian_model_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparzen_model_1\u001b[0m\u001b[1;33m,\u001b[0m                                                  \u001b[0mview_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_numbers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-f93ad7644016>\u001b[0m in \u001b[0;36mtrain_classifiers\u001b[1;34m(X_train, y_train)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mbayesian_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimate_bandwidth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mparzen_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparzen_estimation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-16ae302322a4>\u001b[0m in \u001b[0;36mestimate_bandwidth\u001b[1;34m(x_train, y_train)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mmodelos_kde_hi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparzen_estimation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_trn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_trn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mpriori_probability\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m7.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mpredict_hi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelos_kde_hi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpriori_probability\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mprecision_of_h\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_hi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-2cda2a6491dd>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(models, x_validation, priori)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mposteriori\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m                                    \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpriori\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0msum_evidences\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mprediction_cls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposteriori\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\kde.py\u001b[0m in \u001b[0;36mscore_samples\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;31m# For it to be a probability, we must scale it.  For this reason\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;31m# we'll also scale atol.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m         \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[0matol_N\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matol\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    431\u001b[0m                                       force_all_finite)\n\u001b[0;32m    432\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "output_1 = []\n",
    "output_2 = []\n",
    "output_3 = []\n",
    "\n",
    "for i in range(30):\n",
    "    # outputs by iteration\n",
    "    iter_output_1 = []\n",
    "    iter_output_2 = []\n",
    "    iter_output_3 = []\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=i)\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y_numbers):\n",
    "        # shape view\n",
    "        view_1 = pd.DataFrame(X).iloc[:, :6].values\n",
    "\n",
    "        # RGB view\n",
    "        view_2 = pd.DataFrame(X).iloc[:, 6:].values\n",
    "\n",
    "        # complete view\n",
    "        view_3 = X\n",
    "        \n",
    "        bayesian_model_1, parzen_model_1 = train_classifiers(view_1[train_index], y_numbers[train_index])\n",
    "        hit_rate_1 = get_sum_classifier_hit_rate(bayesian_model_1, parzen_model_1, \\\n",
    "                                                 view_1[test_index], y_numbers[test_index])\n",
    "        \n",
    "        iter_output_1.append(hit_rate_1)\n",
    "        \n",
    "        bayesian_model_2, parzen_model_2 = train_classifiers(view_2[train_index], y_numbers[train_index])\n",
    "        hit_rate_2 = get_sum_classifier_hit_rate(bayesian_model_2, parzen_model_2, \\\n",
    "                                                 view_2[test_index], y_numbers[test_index])\n",
    "        \n",
    "        iter_output_2.append(hit_rate_2)\n",
    "        \n",
    "        bayesian_model_3, parzen_model_3 = train_classifiers(view_3[train_index], y_numbers[train_index])\n",
    "        hit_rate_3 = get_sum_classifier_hit_rate(bayesian_model_3, parzen_model_3, \\\n",
    "                                                 view_3[test_index], y_numbers[test_index])\n",
    "        \n",
    "        iter_output_3.append(hit_rate_3)\n",
    "\n",
    "    output_1.append(iter_output_1)\n",
    "    output_2.append(iter_output_2)\n",
    "    output_3.append(iter_output_3)\n",
    "\n",
    "with open('output/sum_v1', 'w') as output_file_1:\n",
    "    wr = csv.writer(output_file_1, quoting=csv.QUOTE_NONE)\n",
    "    for row in output_1:\n",
    "        wr.writerow(row)\n",
    "\n",
    "with open('output/sum_v2', 'w') as output_file_2:\n",
    "    wr = csv.writer(output_file_2, quoting=csv.QUOTE_NONE)\n",
    "    for row in output_2:\n",
    "        wr.writerow(row)\n",
    "\n",
    "with open('output/sum_v3', 'w') as output_file_3:\n",
    "    wr = csv.writer(output_file_3, quoting=csv.QUOTE_NONE)\n",
    "    for row in output_3:\n",
    "        wr.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
